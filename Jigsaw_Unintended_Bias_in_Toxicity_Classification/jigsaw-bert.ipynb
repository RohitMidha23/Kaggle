{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\nimport re\nimport gc\nimport sys\nimport time\nimport warnings\nimport json\nimport torch\nimport emoji\nimport random\nimport unicodedata\nimport multiprocessing\nimport seaborn as sns\nfrom functools import partial, lru_cache\nfrom tqdm import tqdm_notebook\nfrom wordcloud import WordCloud, STOPWORDS\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\ntrain = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\nsub = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')\nimport os\nprint(os.listdir(\"../input/nvidiaapex/repository/NVIDIA-apex-39e153a\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Installing Nvidia Apex\n! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport pkg_resources\nimport seaborn as sns\nimport time\nimport scipy.stats as stats\nimport gc\nimport re\nimport operator \nimport sys\nfrom sklearn import metrics\nfrom sklearn import model_selection\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom nltk.stem import PorterStemmer\nfrom sklearn.metrics import roc_auc_score\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom tqdm import tqdm, tqdm_notebook\nimport os\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport warnings\nwarnings.filterwarnings(action='once')\nimport pickle\nfrom apex import amp\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device=torch.device('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 220\nSEED = 23\nEPOCHS = 1\nDATA_DIR = \"../input/jigsaw-unintended-bias-in-toxicity-classification\"\nINPUT_DIR = \"../input\"\nWORK_DIR = \"../working/\"\nLOAD = 1000000                         \nVALIDATION = 100000  \nTOXICITY_COLUMN = 'target'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"PACKAGE_DIR = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\nsys.path.append(PACKAGE_DIR)\n\nfrom pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\nfrom pytorch_pretrained_bert import BertConfig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\nconvert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n    BERT_MODEL_PATH + 'bert_model.ckpt',\nBERT_MODEL_PATH + 'bert_config.json',\nWORK_DIR + 'pytorch_model.bin')\n\nshutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_config = BertConfig('../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'+'bert_config.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_lines(example):\n    tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n    MAX_SEQ_LENGTH=220\n    MAX_SEQ_LENGTH -=2\n    all_tokens = []\n    longer = 0\n    for text in example:\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>MAX_SEQ_LENGTH:\n            tokens_a = tokens_a[:MAX_SEQ_LENGTH]\n            longer += 1\n        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (MAX_SEQ_LENGTH - len(tokens_a))\n        all_tokens.append(one_token)\n    #print(longer)\n    return np.array(all_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\ntrain = train.sample(LOAD+VALIDATION,random_state=SEED)\nprint('[INFO]Loaded %d records' % len(train))\n\ntrain['comment_text'] = train['comment_text'].astype(str) \n\nwith multiprocessing.Pool(processes=2) as pool:\n     sequences = pool.map(convert_lines, train[\"comment_text\"].fillna(\"NAN\"))\n        \n#sequences = convert_lines(train[\"comment_text\"].fillna(\"NAN\"),MAX_SEQUENCE_LENGTH,tokenizer)\ntrain = train.fillna(0)\n# List all identities\nidentities = ['male','female','transgender','other_gender','heterosexual','homosexual_gay_or_lesbian',\n              'bisexual','other_sexual_orientation','christian','jewish','muslim','hindu','buddhist',\n              'atheist','other_religion','black','white','asian','latino','other_race_or_ethnicity',\n              'physical_disability','intellectual_or_learning_disability','psychiatric_or_mental_illness',\n              'other_disability']\nraces = ['black','white','asian','latino','other_race_or_ethnicity']\nreligions = ['atheist', 'buddhist', 'christian', 'hindu', 'muslim', 'jewish','other_religion']\nsexual_orientation = ['heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation']\n\ntrain = train.drop(['comment_text'],axis=1)\n# convert target to 0,1\ntrain['target']=(train['target']>=0.5).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = sequences[:LOAD]                \ny = train['target'].values[:LOAD]\nX_val = sequences[LOAD:]                \ny_val = train['target'].values[LOAD:]\ntest_df = train.tail(VALIDATION).copy()\ntrain_df = train.head(LOAD)\ntrain_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_model(): \n    lr=2e-5\n    batch_size = 32\n    accumulation_steps=2\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    model = BertForSequenceClassification.from_pretrained(\"../working\",cache_dir=None,num_labels=1)\n    model.zero_grad()\n    model = model.to(device)\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ]\n\n    train = train_dataset\n\n    num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n\n    optimizer = BertAdam(optimizer_grouped_parameters,\n                         lr=lr,\n                         warmup=0.05,\n                         t_total=num_train_optimization_steps)\n\n    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUPUT_MODEL_FILE = \"bert_pytorch.bin\"\n\ninit_model()\n\nmodel=model.train()\n\ntq = tqdm_notebook(range(EPOCHS))\nfor epoch in tq:\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    avg_loss = 0.\n    avg_accuracy = 0.\n    lossf=None\n    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n    optimizer.zero_grad()\n    for i,(x_batch, y_batch) in tk0:\n        y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n            optimizer.step()                            # Now we can do an optimizer step\n            optimizer.zero_grad()\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()\n        else:\n            lossf = loss.item()\n        tk0.set_postfix(loss = lossf)\n        avg_loss += loss.item() / len(train_loader)\n        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n\n\ntorch.save(model.state_dict(), OUTPUT_MODEL_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run validation\n# The following 2 lines are not needed but show how to download the model for prediction\nmodel = BertForSequenceClassification(bert_config,num_labels=len(y_columns))\nmodel.load_state_dict(torch.load(output_model_file ))\nmodel.to(device)\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.eval()\nvalid_preds = np.zeros((len(X_val)))\nvalid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\nvalid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n\ntk0 = tqdm_notebook(valid_loader)\nfor i,(x_batch,)  in enumerate(tk0):\n    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From baseline kernel\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]>0.5\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n\n\n\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]>0.5]\n    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nMODEL_NAME = 'model1'\ntest_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\nTOXICITY_COLUMN = 'target'\nbias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\nbias_metrics_df\nget_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}